{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deteksi Emosi Pengguna Twitter\n",
    "\n",
    "Deteksi emosi merupakan salah satu permasalahan yang dihadapi pada ***Natural Language Processing*** (NLP). Alasanya diantaranya adalah kurangnya dataset berlabel untuk mengklasifikasikan emosi berdasarkan data twitter. Selain itu, sifat dari data twitter yang dapat memiliki banyak label emosi (***multi-class***). Manusia memiliki berbagai emosi dan sulit untuk mengumpulkan data yang cukup untuk setiap emosi. Oleh karena itu, masalah ketidakseimbangan kelas akan muncul (***class imbalance***). Pada Ujian Tengah Semester (UTS) kali ini, Anda telah disediakan dataset teks twitter yang sudah memiliki label untuk beberapa kelas emosi. Tugas utama Anda adalah membuat model yang mumpuni untuk kebutuhan klasifikasi emosi berdasarkan teks.\n",
    "\n",
    "### Informasi Data\n",
    "\n",
    "Dataset yang akan digunakan adalah ****tweet_emotion.csv***. Berikut merupakan informasi tentang dataset yang dapat membantu Anda.\n",
    "\n",
    "- Total data: 40000 data\n",
    "- Label emosi: anger, boredom, empty, enthusiasm, fun, happiness, hate, love, neutral, relief, sadness, surprise, worry\n",
    "- Jumlah data untuk setiap label tidak sama (***class imbalance***)\n",
    "- Terdapat 3 kolom = 'tweet_id', 'sentiment', 'content'\n",
    "\n",
    "### Penilaian UTS\n",
    "\n",
    "UTS akan dinilai berdasaarkan 4 proses yang akan Anda lakukan, yaitu pra pengolahan data, ektraksi fitur, pembuatan model machine learning, dan evaluasi.\n",
    "\n",
    "#### Pra Pengolahan Data\n",
    "\n",
    "> **Perhatian**\n",
    "> \n",
    "> Sebelum Anda melakukan sesuatu terhadap data Anda, pastikan data yang Anda miliki sudah \"baik\", bebas dari data yang hilang, menggunakan tipe data yang sesuai, dan sebagainya.\n",
    ">\n",
    "\n",
    "Data tweeter yang ada dapatkan merupakan sebuah data mentah, maka beberapa hal dapat Anda lakukan (namun tidak terbatas pada) yaitu,\n",
    "\n",
    "1. Case Folding\n",
    "2. Tokenizing\n",
    "3. Filtering\n",
    "4. Stemming\n",
    "\n",
    "*CATATAN: PADA DATA TWITTER TERDAPAT *MENTION* (@something) YANG ANDA HARUS TANGANI SEBELUM MASUK KE TAHAP EKSTRAKSI FITUR*\n",
    "\n",
    "#### Ekstrasi Fitur\n",
    "\n",
    "Anda dapat menggunakan beberapa metode, diantaranya\n",
    "\n",
    "1. Bag of Words (Count / TF-IDF)\n",
    "2. N-gram\n",
    "3. dan sebagainya\n",
    "\n",
    "#### Pembuatan Model\n",
    "\n",
    "Anda dibebaskan dalam memilih algoritma klasifikasi. Anda dapat menggunakan algoritma yang telah diajarkan didalam kelas atau yang lain, namun dengan catatan. Berdasarkan asas akuntabilitas pada pengembangan model machine learning, Anda harus dapat menjelaskan bagaimana model Anda dapat menghasilkan nilai tertentu.\n",
    "\n",
    "#### Evaluasi\n",
    "\n",
    "Pada proses evaluasi, minimal Anda harus menggunakan metric akurasi. Akan tetapi Anda juga dapat menambahkan metric lain seperti Recall, Precision, F1-Score, detail Confussion Metric, ataupun Area Under Curve (AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lembar Pengerjaan\n",
    "Lembar pengerjaan dimulai dari cell dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweet_emotions.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk \n",
    "import string\n",
    "import re\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (40000, 3)\n",
      "Columns are: Index(['tweet_id', 'sentiment', 'content'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "tweet_df = pd.read_csv('data/tweet_emotions.csv')\n",
    "\n",
    "print('Dataset size:',tweet_df.shape)\n",
    "print('Columns are:',tweet_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   content    40000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>Tweet_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on your call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>dannycastillo We want to trade with someone who has Houston tickets but no one will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends</td>\n",
       "      <td>Repinging ghostridah why didnt you go to prom BC my bf didnt like my friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about an old friend who I want. but he's married now. da...</td>\n",
       "      <td>I should be sleep but im not thinking about an old friend who I want but hes married now damn am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>Hmmm httpwwwdjherocom is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "      <td>charviray Charlene my love I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "      <td>kelcouch Im sorry  at least its Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment  \\\n",
       "0  1956967341       empty   \n",
       "1  1956967666     sadness   \n",
       "2  1956967696     sadness   \n",
       "3  1956967789  enthusiasm   \n",
       "4  1956968416     neutral   \n",
       "5  1956968477       worry   \n",
       "6  1956968487     sadness   \n",
       "7  1956968636       worry   \n",
       "8  1956969035     sadness   \n",
       "9  1956969172     sadness   \n",
       "\n",
       "                                                                                               content  \\\n",
       "0         @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                         Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                                  Funeral ceremony...gloomy friday...   \n",
       "3                                                                 wants to hang out with friends SOON!   \n",
       "4               @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "5                 Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends   \n",
       "6  I should be sleep, but im not! thinking about an old friend who I want. but he's married now. da...   \n",
       "7                                                                 Hmmm. http://www.djhero.com/ is down   \n",
       "8                                                              @charviray Charlene my love. I miss you   \n",
       "9                                                           @kelcouch I'm sorry  at least it's Friday?   \n",
       "\n",
       "                                                                                           Tweet_punct  \n",
       "0            tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part   \n",
       "1                                               Layin n bed with a headache  ughhhhwaitin on your call  \n",
       "2                                                                        Funeral ceremonygloomy friday  \n",
       "3                                                                  wants to hang out with friends SOON  \n",
       "4                  dannycastillo We want to trade with someone who has Houston tickets but no one will  \n",
       "5                         Repinging ghostridah why didnt you go to prom BC my bf didnt like my friends  \n",
       "6  I should be sleep but im not thinking about an old friend who I want but hes married now damn am...  \n",
       "7                                                                        Hmmm httpwwwdjherocom is down  \n",
       "8                                                                charviray Charlene my love I miss you  \n",
       "9                                                               kelcouch Im sorry  at least its Friday  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_punct'] = df['content'].apply(lambda x: remove_punct(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>Tweet_punct</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
       "      <td>[tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on your call</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>dannycastillo We want to trade with someone who has Houston tickets but no one will</td>\n",
       "      <td>[dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment  \\\n",
       "0  1956967341       empty   \n",
       "1  1956967666     sadness   \n",
       "2  1956967696     sadness   \n",
       "3  1956967789  enthusiasm   \n",
       "4  1956968416     neutral   \n",
       "\n",
       "                                                                                        content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                           Funeral ceremony...gloomy friday...   \n",
       "3                                                          wants to hang out with friends SOON!   \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "                                                                                 Tweet_punct  \\\n",
       "0  tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part    \n",
       "1                                     Layin n bed with a headache  ughhhhwaitin on your call   \n",
       "2                                                              Funeral ceremonygloomy friday   \n",
       "3                                                        wants to hang out with friends SOON   \n",
       "4        dannycastillo We want to trade with someone who has Houston tickets but no one will   \n",
       "\n",
       "                                                                                       Tweet_tokenized  \n",
       "0  [tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...  \n",
       "1                                     [layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]  \n",
       "2                                                                    [funeral, ceremonygloomy, friday]  \n",
       "3                                                          [wants, to, hang, out, with, friends, soon]  \n",
       "4  [dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    return text\n",
    "\n",
    "df['Tweet_tokenized'] = df['Tweet_punct'].apply(lambda x: tokenization(x.lower()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "#stopword.extend(['yr', 'year', 'woman', 'man', 'girl','boy','one', 'two', 'sixteen', 'yearold', 'fu', 'weeks', 'week',\n",
    "#               'treatment', 'associated', 'patients', 'may','day', 'case','old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>Tweet_punct</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "      <th>Tweet_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
       "      <td>[tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...</td>\n",
       "      <td>[tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on your call</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]</td>\n",
       "      <td>[layin, n, bed, headache, ughhhhwaitin, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon]</td>\n",
       "      <td>[wants, hang, friends, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>dannycastillo We want to trade with someone who has Houston tickets but no one will</td>\n",
       "      <td>[dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]</td>\n",
       "      <td>[dannycastillo, want, trade, someone, houston, tickets, one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends</td>\n",
       "      <td>Repinging ghostridah why didnt you go to prom BC my bf didnt like my friends</td>\n",
       "      <td>[repinging, ghostridah, why, didnt, you, go, to, prom, bc, my, bf, didnt, like, my, friends]</td>\n",
       "      <td>[repinging, ghostridah, didnt, go, prom, bc, bf, didnt, like, friends]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about an old friend who I want. but he's married now. da...</td>\n",
       "      <td>I should be sleep but im not thinking about an old friend who I want but hes married now damn am...</td>\n",
       "      <td>[i, should, be, sleep, but, im, not, thinking, about, an, old, friend, who, i, want, but, hes, m...</td>\n",
       "      <td>[sleep, im, thinking, old, friend, want, hes, married, damn, amp, wants, scandalous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>Hmmm httpwwwdjherocom is down</td>\n",
       "      <td>[hmmm, httpwwwdjherocom, is, down]</td>\n",
       "      <td>[hmmm, httpwwwdjherocom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "      <td>charviray Charlene my love I miss you</td>\n",
       "      <td>[charviray, charlene, my, love, i, miss, you]</td>\n",
       "      <td>[charviray, charlene, love, miss]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "      <td>kelcouch Im sorry  at least its Friday</td>\n",
       "      <td>[kelcouch, im, sorry, at, least, its, friday]</td>\n",
       "      <td>[kelcouch, im, sorry, least, friday]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment  \\\n",
       "0  1956967341       empty   \n",
       "1  1956967666     sadness   \n",
       "2  1956967696     sadness   \n",
       "3  1956967789  enthusiasm   \n",
       "4  1956968416     neutral   \n",
       "5  1956968477       worry   \n",
       "6  1956968487     sadness   \n",
       "7  1956968636       worry   \n",
       "8  1956969035     sadness   \n",
       "9  1956969172     sadness   \n",
       "\n",
       "                                                                                               content  \\\n",
       "0         @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                         Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                                  Funeral ceremony...gloomy friday...   \n",
       "3                                                                 wants to hang out with friends SOON!   \n",
       "4               @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "5                 Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends   \n",
       "6  I should be sleep, but im not! thinking about an old friend who I want. but he's married now. da...   \n",
       "7                                                                 Hmmm. http://www.djhero.com/ is down   \n",
       "8                                                              @charviray Charlene my love. I miss you   \n",
       "9                                                           @kelcouch I'm sorry  at least it's Friday?   \n",
       "\n",
       "                                                                                           Tweet_punct  \\\n",
       "0            tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part    \n",
       "1                                               Layin n bed with a headache  ughhhhwaitin on your call   \n",
       "2                                                                        Funeral ceremonygloomy friday   \n",
       "3                                                                  wants to hang out with friends SOON   \n",
       "4                  dannycastillo We want to trade with someone who has Houston tickets but no one will   \n",
       "5                         Repinging ghostridah why didnt you go to prom BC my bf didnt like my friends   \n",
       "6  I should be sleep but im not thinking about an old friend who I want but hes married now damn am...   \n",
       "7                                                                        Hmmm httpwwwdjherocom is down   \n",
       "8                                                                charviray Charlene my love I miss you   \n",
       "9                                                               kelcouch Im sorry  at least its Friday   \n",
       "\n",
       "                                                                                       Tweet_tokenized  \\\n",
       "0  [tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...   \n",
       "1                                     [layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]   \n",
       "2                                                                    [funeral, ceremonygloomy, friday]   \n",
       "3                                                          [wants, to, hang, out, with, friends, soon]   \n",
       "4  [dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]   \n",
       "5         [repinging, ghostridah, why, didnt, you, go, to, prom, bc, my, bf, didnt, like, my, friends]   \n",
       "6  [i, should, be, sleep, but, im, not, thinking, about, an, old, friend, who, i, want, but, hes, m...   \n",
       "7                                                                   [hmmm, httpwwwdjherocom, is, down]   \n",
       "8                                                        [charviray, charlene, my, love, i, miss, you]   \n",
       "9                                                        [kelcouch, im, sorry, at, least, its, friday]   \n",
       "\n",
       "                                                                          Tweet_nonstop  \n",
       "0           [tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]  \n",
       "1                                         [layin, n, bed, headache, ughhhhwaitin, call]  \n",
       "2                                                     [funeral, ceremonygloomy, friday]  \n",
       "3                                                          [wants, hang, friends, soon]  \n",
       "4                          [dannycastillo, want, trade, someone, houston, tickets, one]  \n",
       "5                [repinging, ghostridah, didnt, go, prom, bc, bf, didnt, like, friends]  \n",
       "6  [sleep, im, thinking, old, friend, want, hes, married, damn, amp, wants, scandalous]  \n",
       "7                                                              [hmmm, httpwwwdjherocom]  \n",
       "8                                                     [charviray, charlene, love, miss]  \n",
       "9                                                  [kelcouch, im, sorry, least, friday]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    return text\n",
    "\n",
    "df['Tweet_nonstop'] = df['Tweet_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>Tweet_punct</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "      <th>Tweet_nonstop</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
       "      <td>[tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...</td>\n",
       "      <td>[tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]</td>\n",
       "      <td>[tiffanylu, know, listenin, bad, habit, earlier, start, freakin, part, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on your call</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]</td>\n",
       "      <td>[layin, n, bed, headache, ughhhhwaitin, call]</td>\n",
       "      <td>[layin, n, bed, headach, ughhhhwaitin, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funer, ceremonygloomi, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon]</td>\n",
       "      <td>[wants, hang, friends, soon]</td>\n",
       "      <td>[want, hang, friend, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>dannycastillo We want to trade with someone who has Houston tickets but no one will</td>\n",
       "      <td>[dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]</td>\n",
       "      <td>[dannycastillo, want, trade, someone, houston, tickets, one]</td>\n",
       "      <td>[dannycastillo, want, trade, someon, houston, ticket, one]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment  \\\n",
       "0  1956967341       empty   \n",
       "1  1956967666     sadness   \n",
       "2  1956967696     sadness   \n",
       "3  1956967789  enthusiasm   \n",
       "4  1956968416     neutral   \n",
       "\n",
       "                                                                                        content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                           Funeral ceremony...gloomy friday...   \n",
       "3                                                          wants to hang out with friends SOON!   \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "                                                                                 Tweet_punct  \\\n",
       "0  tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part    \n",
       "1                                     Layin n bed with a headache  ughhhhwaitin on your call   \n",
       "2                                                              Funeral ceremonygloomy friday   \n",
       "3                                                        wants to hang out with friends SOON   \n",
       "4        dannycastillo We want to trade with someone who has Houston tickets but no one will   \n",
       "\n",
       "                                                                                       Tweet_tokenized  \\\n",
       "0  [tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...   \n",
       "1                                     [layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]   \n",
       "2                                                                    [funeral, ceremonygloomy, friday]   \n",
       "3                                                          [wants, to, hang, out, with, friends, soon]   \n",
       "4  [dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]   \n",
       "\n",
       "                                                                 Tweet_nonstop  \\\n",
       "0  [tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]   \n",
       "1                                [layin, n, bed, headache, ughhhhwaitin, call]   \n",
       "2                                            [funeral, ceremonygloomy, friday]   \n",
       "3                                                 [wants, hang, friends, soon]   \n",
       "4                 [dannycastillo, want, trade, someone, houston, tickets, one]   \n",
       "\n",
       "                                                              Tweet_stemmed  \n",
       "0  [tiffanylu, know, listenin, bad, habit, earlier, start, freakin, part, ]  \n",
       "1                              [layin, n, bed, headach, ughhhhwaitin, call]  \n",
       "2                                           [funer, ceremonygloomi, friday]  \n",
       "3                                                [want, hang, friend, soon]  \n",
       "4                [dannycastillo, want, trade, someon, houston, ticket, one]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_stemmed'] = df['Tweet_nonstop'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>Tweet_punct</th>\n",
       "      <th>Tweet_tokenized</th>\n",
       "      <th>Tweet_nonstop</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part</td>\n",
       "      <td>[tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...</td>\n",
       "      <td>[tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]</td>\n",
       "      <td>[tiffanylu, know, listenin, bad, habit, earlier, start, freakin, part, ]</td>\n",
       "      <td>[tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on your call</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]</td>\n",
       "      <td>[layin, n, bed, headache, ughhhhwaitin, call]</td>\n",
       "      <td>[layin, n, bed, headach, ughhhhwaitin, call]</td>\n",
       "      <td>[layin, n, bed, headache, ughhhhwaitin, call]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funer, ceremonygloomi, friday]</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON</td>\n",
       "      <td>[wants, to, hang, out, with, friends, soon]</td>\n",
       "      <td>[wants, hang, friends, soon]</td>\n",
       "      <td>[want, hang, friend, soon]</td>\n",
       "      <td>[want, hang, friend, soon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>dannycastillo We want to trade with someone who has Houston tickets but no one will</td>\n",
       "      <td>[dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]</td>\n",
       "      <td>[dannycastillo, want, trade, someone, houston, tickets, one]</td>\n",
       "      <td>[dannycastillo, want, trade, someon, houston, ticket, one]</td>\n",
       "      <td>[dannycastillo, want, trade, someone, houston, ticket, one]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment  \\\n",
       "0  1956967341       empty   \n",
       "1  1956967666     sadness   \n",
       "2  1956967696     sadness   \n",
       "3  1956967789  enthusiasm   \n",
       "4  1956968416     neutral   \n",
       "\n",
       "                                                                                        content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                           Funeral ceremony...gloomy friday...   \n",
       "3                                                          wants to hang out with friends SOON!   \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "                                                                                 Tweet_punct  \\\n",
       "0  tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part    \n",
       "1                                     Layin n bed with a headache  ughhhhwaitin on your call   \n",
       "2                                                              Funeral ceremonygloomy friday   \n",
       "3                                                        wants to hang out with friends SOON   \n",
       "4        dannycastillo We want to trade with someone who has Houston tickets but no one will   \n",
       "\n",
       "                                                                                       Tweet_tokenized  \\\n",
       "0  [tiffanylue, i, know, i, was, listenin, to, bad, habit, earlier, and, i, started, freakin, at, h...   \n",
       "1                                     [layin, n, bed, with, a, headache, ughhhhwaitin, on, your, call]   \n",
       "2                                                                    [funeral, ceremonygloomy, friday]   \n",
       "3                                                          [wants, to, hang, out, with, friends, soon]   \n",
       "4  [dannycastillo, we, want, to, trade, with, someone, who, has, houston, tickets, but, no, one, will]   \n",
       "\n",
       "                                                                 Tweet_nonstop  \\\n",
       "0  [tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]   \n",
       "1                                [layin, n, bed, headache, ughhhhwaitin, call]   \n",
       "2                                            [funeral, ceremonygloomy, friday]   \n",
       "3                                                 [wants, hang, friends, soon]   \n",
       "4                 [dannycastillo, want, trade, someone, houston, tickets, one]   \n",
       "\n",
       "                                                              Tweet_stemmed  \\\n",
       "0  [tiffanylu, know, listenin, bad, habit, earlier, start, freakin, part, ]   \n",
       "1                              [layin, n, bed, headach, ughhhhwaitin, call]   \n",
       "2                                           [funer, ceremonygloomi, friday]   \n",
       "3                                                [want, hang, friend, soon]   \n",
       "4                [dannycastillo, want, trade, someon, houston, ticket, one]   \n",
       "\n",
       "                                                              Tweet_lemmatized  \n",
       "0  [tiffanylue, know, listenin, bad, habit, earlier, started, freakin, part, ]  \n",
       "1                                [layin, n, bed, headache, ughhhhwaitin, call]  \n",
       "2                                            [funeral, ceremonygloomy, friday]  \n",
       "3                                                   [want, hang, friend, soon]  \n",
       "4                  [dannycastillo, want, trade, someone, houston, ticket, one]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_lemmatized'] = df['Tweet_nonstop'].apply(lambda x: lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    tokens = re.split('\\W+', text_rc)    # tokenization\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = clean_text(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "#vectorizer.fit(data)\n",
    "#vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 Number of tweets has 45306 words\n"
     ]
    }
   ],
   "source": [
    "countVectorizer = CountVectorizer(analyzer=clean_text) \n",
    "countVector = countVectorizer.fit_transform(df['content'])\n",
    "print('{} Number of tweets has {} words'.format(countVector.shape[0], countVector.shape[1]))\n",
    "#print(countVectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaaaaaamaz</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>...</th>\n",
       "      <th>½we</th>\n",
       "      <th>½whi</th>\n",
       "      <th>½who</th>\n",
       "      <th>½whyyi</th>\n",
       "      <th>½y</th>\n",
       "      <th>½you</th>\n",
       "      <th>½z</th>\n",
       "      <th>½ï</th>\n",
       "      <th>â</th>\n",
       "      <th>ï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaa  aaaa  aaaaa  aaaaaaaa  aaaaaaaaaaa  aaaaaaaaaahhhhhhhh  \\\n",
       "0  1   0    0     0      0         0            0                   0   \n",
       "1  0   0    0     0      0         0            0                   0   \n",
       "2  0   0    0     0      0         0            0                   0   \n",
       "3  0   0    0     0      0         0            0                   0   \n",
       "4  0   0    0     0      0         0            0                   0   \n",
       "\n",
       "   aaaaaaaaaamaz  aaaaaaaafternoon  ...  ½we  ½whi  ½who  ½whyyi  ½y  ½you  \\\n",
       "0              0                 0  ...    0     0     0       0   0     0   \n",
       "1              0                 0  ...    0     0     0       0   0     0   \n",
       "2              0                 0  ...    0     0     0       0   0     0   \n",
       "3              0                 0  ...    0     0     0       0   0     0   \n",
       "4              0                 0  ...    0     0     0       0   0     0   \n",
       "\n",
       "   ½z  ½ï  â  ï  \n",
       "0   0   0  0  0  \n",
       "1   0   0  0  0  \n",
       "2   0   0  0  0  \n",
       "3   0   0  0  0  \n",
       "4   0   0  0  0  \n",
       "\n",
       "[5 rows x 45306 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "count_vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaaaaaamaz</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>aaaaaaaahhhhhhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>½we</th>\n",
       "      <th>½whi</th>\n",
       "      <th>½who</th>\n",
       "      <th>½whyyi</th>\n",
       "      <th>½y</th>\n",
       "      <th>½you</th>\n",
       "      <th>½z</th>\n",
       "      <th>½ï</th>\n",
       "      <th>â</th>\n",
       "      <th>ï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 45305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaaa  aaaaaaaa  aaaaaaaaaaa  aaaaaaaaaahhhhhhhh  \\\n",
       "0       0    0     0      0         0            0                   0   \n",
       "1       0    0     0      0         0            0                   0   \n",
       "2       0    0     0      0         0            0                   0   \n",
       "3       0    0     0      0         0            0                   0   \n",
       "4       0    0     0      0         0            0                   0   \n",
       "...    ..  ...   ...    ...       ...          ...                 ...   \n",
       "39995   0    0     0      0         0            0                   0   \n",
       "39996   0    0     0      0         0            0                   0   \n",
       "39997   0    0     0      0         0            0                   0   \n",
       "39998   0    0     0      0         0            0                   0   \n",
       "39999   0    0     0      0         0            0                   0   \n",
       "\n",
       "       aaaaaaaaaamaz  aaaaaaaafternoon  aaaaaaaahhhhhhhh  ...  ½we  ½whi  \\\n",
       "0                  0                 0                 0  ...    0     0   \n",
       "1                  0                 0                 0  ...    0     0   \n",
       "2                  0                 0                 0  ...    0     0   \n",
       "3                  0                 0                 0  ...    0     0   \n",
       "4                  0                 0                 0  ...    0     0   \n",
       "...              ...               ...               ...  ...  ...   ...   \n",
       "39995              0                 0                 0  ...    0     0   \n",
       "39996              0                 0                 0  ...    0     0   \n",
       "39997              0                 0                 0  ...    0     0   \n",
       "39998              0                 0                 0  ...    0     0   \n",
       "39999              0                 0                 0  ...    0     0   \n",
       "\n",
       "       ½who  ½whyyi  ½y  ½you  ½z  ½ï  â  ï  \n",
       "0         0       0   0     0   0   0  0  0  \n",
       "1         0       0   0     0   0   0  0  0  \n",
       "2         0       0   0     0   0   0  0  0  \n",
       "3         0       0   0     0   0   0  0  0  \n",
       "4         0       0   0     0   0   0  0  0  \n",
       "...     ...     ...  ..   ...  ..  .. .. ..  \n",
       "39995     0       0   0     0   0   0  0  0  \n",
       "39996     0       0   0     0   0   0  0  0  \n",
       "39997     0       0   0     0   0   0  0  0  \n",
       "39998     0       0   0     0   0   0  0  0  \n",
       "39999     0       0   0     0   0   0  0  0  \n",
       "\n",
       "[40000 rows x 45305 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pisahkan label dan fitur\n",
    "X = count_vect_df.iloc[:,1:]\n",
    "y = count_vect_df.iloc[:,0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7000/2380488494.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = encode.fit_transform(df[col])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aaaaaaaa</th>\n",
       "      <th>aaaaaaaaaaa</th>\n",
       "      <th>aaaaaaaaaahhhhhhhh</th>\n",
       "      <th>aaaaaaaaaamaz</th>\n",
       "      <th>aaaaaaaafternoon</th>\n",
       "      <th>aaaaaaaahhhhhhhh</th>\n",
       "      <th>...</th>\n",
       "      <th>½we</th>\n",
       "      <th>½whi</th>\n",
       "      <th>½who</th>\n",
       "      <th>½whyyi</th>\n",
       "      <th>½y</th>\n",
       "      <th>½you</th>\n",
       "      <th>½z</th>\n",
       "      <th>½ï</th>\n",
       "      <th>â</th>\n",
       "      <th>ï</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 45305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaaa  aaaaaaaa  aaaaaaaaaaa  aaaaaaaaaahhhhhhhh  \\\n",
       "0       0    0     0      0         0            0                   0   \n",
       "1       0    0     0      0         0            0                   0   \n",
       "2       0    0     0      0         0            0                   0   \n",
       "3       0    0     0      0         0            0                   0   \n",
       "4       0    0     0      0         0            0                   0   \n",
       "...    ..  ...   ...    ...       ...          ...                 ...   \n",
       "39995   0    0     0      0         0            0                   0   \n",
       "39996   0    0     0      0         0            0                   0   \n",
       "39997   0    0     0      0         0            0                   0   \n",
       "39998   0    0     0      0         0            0                   0   \n",
       "39999   0    0     0      0         0            0                   0   \n",
       "\n",
       "       aaaaaaaaaamaz  aaaaaaaafternoon  aaaaaaaahhhhhhhh  ...  ½we  ½whi  \\\n",
       "0                  0                 0                 0  ...    0     0   \n",
       "1                  0                 0                 0  ...    0     0   \n",
       "2                  0                 0                 0  ...    0     0   \n",
       "3                  0                 0                 0  ...    0     0   \n",
       "4                  0                 0                 0  ...    0     0   \n",
       "...              ...               ...               ...  ...  ...   ...   \n",
       "39995              0                 0                 0  ...    0     0   \n",
       "39996              0                 0                 0  ...    0     0   \n",
       "39997              0                 0                 0  ...    0     0   \n",
       "39998              0                 0                 0  ...    0     0   \n",
       "39999              0                 0                 0  ...    0     0   \n",
       "\n",
       "       ½who  ½whyyi  ½y  ½you  ½z  ½ï  â  ï  \n",
       "0         0       0   0     0   0   0  0  0  \n",
       "1         0       0   0     0   0   0  0  0  \n",
       "2         0       0   0     0   0   0  0  0  \n",
       "3         0       0   0     0   0   0  0  0  \n",
       "4         0       0   0     0   0   0  0  0  \n",
       "...     ...     ...  ..   ...  ..  .. .. ..  \n",
       "39995     0       0   0     0   0   0  0  0  \n",
       "39996     0       0   0     0   0   0  0  0  \n",
       "39997     0       0   0     0   0   0  0  0  \n",
       "39998     0       0   0     0   0   0  0  0  \n",
       "39999     0       0   0     0   0   0  0  0  \n",
       "\n",
       "[40000 rows x 45305 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Encode Fitur\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def feature_encode(df):\n",
    "    encode = LabelEncoder()\n",
    "    for col in df:\n",
    "        df[col] = encode.fit_transform(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "X = feature_encode(X)\n",
    "display(X)\n",
    "\n",
    "# Encode Label\n",
    "encode = LabelEncoder()\n",
    "y = encode.fit_transform(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.45 GiB for an array with shape (45305, 28000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_7000/2887343133.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split train test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Initiate Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdt_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2441\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2443\u001b[1;33m     return list(\n\u001b[0m\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[0;32m   2445\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2443\u001b[0m     return list(\n\u001b[0;32m   2444\u001b[0m         chain.from_iterable(\n\u001b[1;32m-> 2445\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2446\u001b[0m         )\n\u001b[0;32m   2447\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_pandas_indexing\u001b[1;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;31m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;31m# copy that will not raise SettingWithCopyWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;31m# check whether we should index with loc or iloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3613\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3615\u001b[1;33m         new_data = self._mgr.take(\n\u001b[0m\u001b[0;32m   3616\u001b[0m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3617\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         return self.reindex_indexer(\n\u001b[0m\u001b[0;32m    866\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m    678\u001b[0m             )\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             new_blocks = [\n\u001b[0m\u001b[0;32m    681\u001b[0m                 blk.take_nd(\n\u001b[0;32m    682\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             new_blocks = [\n\u001b[1;32m--> 681\u001b[1;33m                 blk.take_nd(\n\u001b[0m\u001b[0;32m    682\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1143\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m         new_values = algos.take_nd(\n\u001b[0m\u001b[0;32m   1146\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\array_algos\\take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.45 GiB for an array with shape (45305, 28000) and data type int64"
     ]
    }
   ],
   "source": [
    "# Split train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "\n",
    "# Initiate Model\n",
    "dt_entropy = DecisionTreeClassifier(criterion='entropy')\n",
    "dt_gini = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# Fit model\n",
    "# Entropy\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "y_pred_entropy_train = dt_entropy.predict(X_train)\n",
    "y_pred_entropy = dt_entropy.predict(X_test)\n",
    "\n",
    "# Gini\n",
    "dt_gini.fit(X_train, y_train)\n",
    "y_pred_gini_train = dt_gini.predict(X_train)\n",
    "y_pred_gini = dt_gini.predict(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "# Entropy\n",
    "acc_entropy_train = accuracy_score(y_train, y_pred_entropy_train)\n",
    "acc_entropy = accuracy_score(y_test, y_pred_entropy)\n",
    "\n",
    "# Gini\n",
    "acc_gini_train = accuracy_score(y_train, y_pred_gini_train)\n",
    "acc_gini = accuracy_score(y_test, y_pred_gini)\n",
    "\n",
    "print(f'Akurasi Entropy Train: {acc_entropy_train}')\n",
    "print(f'Akurasi Entropy: {acc_entropy}')\n",
    "print('\\n')\n",
    "print(f'Akurasi Gini Train: {acc_gini_train}')\n",
    "print(f'Akurasi Gini: {acc_gini}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57bc2b6ce032b5f0e93daa91901b7ea38a856826ef43aa9e95b6d3999f5310df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
